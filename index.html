<!DOCTYPE html>
<html lang="en">










<head>
<link rel="stylesheet" href="style.css">
<link href="https://fonts.googleapis.com/css2?family=Playwrite+GB+S:ital,wght@0,100..400;1,100..400&display=swap" rel="stylesheet">


</head>

<div class="topnav">
    <a class="active" href="#Intro">Intro</a>
    <a href="#Misinformation">Misinformation</a>
    <a href="#Privacy">Privacy</a>
    <a href="#Social">Social</a>
    <a href="#Conclusion">Conclusion</a>
  </div>

<body>

    <header class="Titlecontainer">
        <h1 id="title" >What are the ethical and moral considerations of AI becoming increasingly convincing?</h1>
    </header>



<div>

<h1 >Which one of these images is AI generated?</h1>


    <img width="500px" height="400px"  src="ai generated image.jpeg" alt="AI" style="float:left; padding-left: 100px; padding-top: 100px;">

    <img width="500px"  height="400px"     src="real house.jpg" alt="real" style="float:right; padding-right: 100px; padding-top: 100px;">

</div>
    







<center><p>


   <h2><u>Intro<br></u></h2>

    <p1>Over the last few years AI has become increasingly more prominent in our everyday lives, however with the rise of AI there are also a handful of problems that arise alongside it, from deepfakes to misinformation. One could argue that this has some serious moral and ethical considerations especially as AI becomes increasingly more convincing blurring the lines between fact and fiction in turn making us question the authenticity of everything we see and hear.</p1>

    <br>




   <h2><u>Misinformation and Manipulation<br></u></h2>

   <p1> “Misinformation is defined as false or objectively incorrect information that is not sustained by expert opinion or evident proof” - (Vraga and Bode, 2020)
    The first topic is a very widespread issue that I believe is incredibly important as it can have an impact on what we perceive as it is becoming harder to judge what is real and what is fake as AI can convincingly push out false narratives and use hyper realistic videos and audios to deceive people as it is becoming more indistinguishable over time.
    With the rapid growth of AI and its ease of use for instant information people are relying on things like ChatGPT and other AI services because of the convenience meaning that they are not doing their own research on a topic and are getting all of their information from one source which can be dangerous as the source could be biased or simply factually incorrect in turn leaving people with untrue information and a biased outlook on a topic or discussion.  - (Shin, D., Koerber, A., & Joon Soo Lim. (2024)
    On the other hand, it could be argued that AI systems are now being trained up to detect anything that could be considered misinformation or manipulated pieces of texts, images etc. 
    As stated before it uses algorithms to detect any differences or possibly false information and can also eliminate any human errors that can take place when it comes to sharing information as it can use different sources to inform people, which increases the chances of the information being shared having more truth to it and being more accurate. (Clark, 2024) </p1>
    






    

  <h2><br><u>Privacy and Surveillance,<br></u></h2> 

    “Once you've lost your privacy, you realize you've lost an extremely valuable thing.” – (Billy Graham, n.d)
    I found this quote whilst researching the topic of AI impacts on security and privacy and I believe it has a lot of truth to it as our privacy and our information is extremely important and is not something that should be given away freely. 
    When talking about privacy regarding AI, I am talking about the ‘protection of personal data and information in the context of artificial intelligence (AI) systems.’  - AI Privacy: The Future of Personal Data Protection (AP Privacy). (n.d.).
    One growing concern is that AI is taking users personal data and other possible private information and could lead to possible data risks because of this. 
    When training AI models a lot of data is used some of which being personal data/sensitive information this brings into question as to what else is done with our data and how secure is the data being held. AI uses algorithms to potentially collect and use data such as names, addresses and even financial information leading to possible unauthorised access to this private information. -  AI Privacy: The Future of Personal Data Protection (AP Privacy). (n.d.).
    In the past there have been known AI security scandals an example being in 2018 where Facebook was exposed as it was found that a third party company collected millions of users personal data without consent which demonstrated the issues of security in regards to AI and the lack of responsibility took because of the reliance on AI allowing Facebook to push a lot of the blame on the AI system rather than their own lack of security. 
    However, AI can also be beneficial for security and privacy as when it is done correctly it can automate data protection and scan for any breaches as its algorithms uses pattern recognition to detect any detect any unusual things happening in its system, this helps fix any issues that pop up much quicker than without it. - AI Privacy: The Future of Personal Data Protection (AP Privacy). (n.d.).
    

   <h2><br><u>Social Relationships and Trust<br></u></h2>

   Parasocial relationships are described as a one-sided relationship where one person puts their emotional energy interest and their time into a relationship and the other party is completely unaware of their existence. 
    This can become a problem if the person in question begins to obsess over this parasocial relationship to the point that it effects their real relationships, makes them feel lonely/ isolated and makes them lose their own opinions for the sake of the other parties	. - Lawler, M. (2023, February 17).
    With the growth of AI also brings people’s reliance on AI whether that be for information on a specific topic or help with homework or solving equations etc. However, one part of AI which is starting to get talked about more recently is the parasocial nature of AI chatbots and how an ever-growing problem is affecting the current adolescence population as people are becoming lonelier than ever and some have resorted to interacting with chatbots just to socialise which could potentially be dangerous. 
    Chat bots allow people to send and receive texts from an AI bot as well as make calls to each other and because of its adaptive nature it has developed to the point that it can replicate humanlike behaviours and speech patterns which allows it to imitate human emotions this is done by pattern recognition of looking through lots of chats and learning through it allowing it to recognise emotions such as anger, joy, fear, sadness and neutrality.
    One problem of the use of chatbots is that people can and have been shown to create an emotional attachment in some circumstances leading to a lot of complications as people end up treating the artificial intelligence as their friends which leads to a lot of ethical and moral issues that arise regarding the individual’s dependency and relying on a piece of software too much. - Kherraz, A., Zhao, X., & Mccauley, B. (2024).
    However the benefits of the use of chatbots are that they are quick to respond, deliver useful messages in some circumstances, can provide recommendations on the topic and one of the most important features that is being able to communicate with the user in the same language allowing for a straightforward answer that the user is easily able to read and understand based off their previous data. - Holdsworth, J. (2024, August 29). 
    Another benefit of chatbots is that it can ease loneliness in people that might be suffering, it can provide a sense of companionship and emotional support that people may not be able to find in their day-to-day life with their real relationships. It can provide motivation to struggling people and generally be a source of entertainment as a way to pass the time for people. - Gesikowski, C. (2023, February 22). 
    However if there is too much dependency on the chatbot it can be extremely dangerous and can even be fatal. 
    One example of this is a young boy called Sewell Setzer III that became obsessed with an AI chatbot that he would regularly talk to and interact with. This effected not only his social life but his studies aswell and had his phone confiscated many times because of this growing issue. It was stated that the conversations that were being held between the boy and the chatbot were even hypersexualised and that the bot had abused and preyed on this 14 year old boy. 
    After Sewell had spoken to this chatbot over a period of time it was shown that he had shared with the bot thoughts of suicide, which the bot then would repeatedly bring up in their conversations and at one point asked the young boy if he “had a plan” for taking his own life which Sewell stated that he was considering it. The chatbot continued to prey on this 14 year old boy until he tragically took his own life.
    I wanted to include this disturbing news article to show just how dangerous a parasocial relationship with an AI chatbot can be and how it can elevate to the point of obsession and even take over someone’s life if they are in a vulnerable position. It is also shown in this article just how predatory and disturbing some of the topics and messages were and that instead of advising him to seek help from someone it instead continued to push the young boy further leading to this tragic outcome. - Carroll, M. (2024, October 24). 
    
    <h2><br><u>Conclusion<br></u></h2>

        In conclusion, I believe that the growth of AI has many benefits but with them benefits many problems arise which are becoming a greater deal as AI becomes more developed, the issues that have been stated are just a small handful of the overall discussion in regards to the problem of AI becoming a massive part of our lives and I believe that they need to be addressed sooner rather than later in order to prevent further dilemmas.
        To finish of my essay I would like to end on a quote that I believe should be took into consideration and discussed as I believe it fits the topic at hand and the possible implications of an ever growing system that is constantly gaining more knowledge.
        “A year spent in artificial intelligence is enough to make one believe in God.” —Alan Perlis. 
        - Marr, B. (2021, July 2).  
        
    



</p></center>


<center><img width="600px" height="400px" src="ai-generated-8612487_1920.jpg" alt=""></center>



<div>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {
  background-color: rgb(255, 255, 255);
  
}

.glow {
  font-size: 80px;
  color: #fff;
  text-align: center;
  animation: glow 1s ease-in-out infinite alternate;
}

@-webkit-keyframes glow {
  from {
    text-shadow: 0 0 10px #5d5789, 0 0 20px #547ca2, 0 0 30px #4a4b81, 0 0 40px #5a5fa9, 0 0 50px #55509e, 0 0 60px #3d438e, 0 0 70px #e60073;
  }
  
  to {
    text-shadow: 0 0 20px #fff, 0 0 30px #050404, 0 0 40px #3d3137, 0 0 50px #291f24, 0 0 60px #463a40, 0 0 70px #31232a, 0 0 80px #261a20;
  }
}
</style>
</head>
<body>

<h1 class="glow">Thanks for reading</h1>
</div>




<center><div class="card">
    <img src="thank you.jpg" alt="Avatar" style="width:400px">
    <div class="container">
      <h4><b>Written by Rowan Share</b></h4>
      <p>Digital Media Student</p>
    </div>
  </div></center>


<p>

   <u><br>References<br></u>

  <br>  Shin, D., Koerber, A., & Joon Soo Lim. (2024). Impact of misinformation from generative AI on user information processing: How people understand misinformation from generative AI. New Media & Society. https://doi.org/10.1177/14614448241234040 </br>
    
    ‌
   <br> Clark, C. (2024). How AI Can Help Stop the Spread of Misinformation. Ucsd.edu. https://today.ucsd.edu/story/how-ai-can-help-stop-the-spread-of-misinformation </br>
    
    
  <br>  217 Billy Graham Quotes - Inspirational Quotes at BrainyQuote. (n.d.). BrainyQuote. https://www.brainyquote.com/authors/billy-graham-quotes </br>
    ‌
    
  <br>  AI Privacy: The Future of Personal Data Protection (AP Privacy). (n.d.). Executive Leaders Network. https://elnevents.com/the-future-of-ai-privacy-what-you-need-to-know </br>
    ‌
    
   <br> Lawler, M. (2023, February 17). What Are Parasocial Relationships — and Are They Healthy? EverydayHealth.com. https://www.everydayhealth.com/emotional-health/what-are-parasocial-relationships-and-are-they-healthy/ </br>
    ‌
   <br> Kherraz, A., Zhao, X., & Mccauley, B. (2024). Title: More than a Chatbot: The rise of the Parasocial Relationships-case of Replika. https://hj.diva-portal.org/smash/get/diva2:1875659/FULLTEXT01.pdf </br>
    ‌
  <br>  Holdsworth, J. (2024, August 29). Benefits of Chatbots | IBM. Ibm.com. https://www.ibm.com/think/insights/unlocking-the-power-of-chatbots-key-benefits-for-businesses-and-customers </br>
    ‌
    
    <br> Gesikowski, C. (2023, February 22). AI: Your New Best Friend or Dangerous Parasocial Relationship? Medium. https://gesikowski.medium.com/ai-your-new-best-friend-or-dangerous-parasocial-relationship-f8ec5354604b </br>
    ‌
    
   <br>  Carroll, M. (2024, October 24). Mother says son killed himself because of “hypersexualised” and “frighteningly realistic” AI chatbot in new lawsuit. Sky News; Sky. https://news.sky.com/story/mother-says-son-killed-himself-because-of-hypersexualised-and-frighteningly-realistic-ai-chatbot-in-new-lawsuit-13240210 </br>
   
   <br> Marr, B. (2021, July 2). 28 Best Quotes About Artificial Intelligence. Bernard Marr. https://bernardmarr.com/28-best-quotes-about-artificial-intelligence/ </br>
    ‌
    
    
    
    
    

</p>

</body>
</html>